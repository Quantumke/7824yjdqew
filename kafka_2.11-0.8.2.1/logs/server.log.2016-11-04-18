[2016-11-04 18:17:38,052] ERROR Closing socket for /127.0.0.1 because of error (kafka.network.Processor)
kafka.common.KafkaException: Wrong request type 16
	at kafka.api.RequestKeys$.deserializerForKey(RequestKeys.scala:64)
	at kafka.network.RequestChannel$Request.<init>(RequestChannel.scala:50)
	at kafka.network.Processor.read(SocketServer.scala:450)
	at kafka.network.Processor.run(SocketServer.scala:340)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:17:38,128] ERROR [KafkaApi-0] error when handling request ConsumerMetadataRequest(kafka-python-default-group,0,4,kafka-python-producer-1) (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:70)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:171)
	at kafka.server.KafkaApis$$anonfun$19.apply(KafkaApis.scala:513)
	at kafka.server.KafkaApis$$anonfun$19.apply(KafkaApis.scala:503)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:92)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:503)
	at kafka.server.KafkaApis.handleConsumerMetadataRequest(KafkaApis.scala:607)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:69)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:59)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:17:55,545] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2016-11-04 18:17:55,547] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2016-11-04 18:17:55,600] INFO [Kafka Server 0], Controlled shutdown succeeded (kafka.server.KafkaServer)
[2016-11-04 18:17:55,602] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2016-11-04 18:17:55,603] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[2016-11-04 18:17:55,607] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[2016-11-04 18:17:55,608] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2016-11-04 18:17:55,610] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2016-11-04 18:17:55,886] INFO [Replica Manager on Broker 0]: Shut down (kafka.server.ReplicaManager)
[2016-11-04 18:17:55,887] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2016-11-04 18:17:55,888] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2016-11-04 18:17:55,892] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[2016-11-04 18:17:55,893] INFO Shutting down. (kafka.log.LogManager)
[2016-11-04 18:17:55,899] INFO Shutdown complete. (kafka.log.LogManager)
[2016-11-04 18:17:55,936] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2016-11-04 18:17:57,020] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-11-04 18:17:57,055] INFO Property broker.id is overridden to 0 (kafka.utils.VerifiableProperties)
[2016-11-04 18:17:57,056] INFO Property log.cleaner.enable is overridden to false (kafka.utils.VerifiableProperties)
[2016-11-04 18:17:57,056] INFO Property log.dirs is overridden to /tmp/kafka-logs (kafka.utils.VerifiableProperties)
[2016-11-04 18:17:57,056] INFO Property log.retention.check.interval.ms is overridden to 300000 (kafka.utils.VerifiableProperties)
[2016-11-04 18:17:57,056] INFO Property log.retention.hours is overridden to 168 (kafka.utils.VerifiableProperties)
[2016-11-04 18:17:57,057] INFO Property log.segment.bytes is overridden to 1073741824 (kafka.utils.VerifiableProperties)
[2016-11-04 18:17:57,057] INFO Property num.io.threads is overridden to 8 (kafka.utils.VerifiableProperties)
[2016-11-04 18:17:57,057] INFO Property num.network.threads is overridden to 3 (kafka.utils.VerifiableProperties)
[2016-11-04 18:17:57,058] INFO Property num.partitions is overridden to 1 (kafka.utils.VerifiableProperties)
[2016-11-04 18:17:57,058] INFO Property num.recovery.threads.per.data.dir is overridden to 1 (kafka.utils.VerifiableProperties)
[2016-11-04 18:17:57,058] INFO Property port is overridden to 9092 (kafka.utils.VerifiableProperties)
[2016-11-04 18:17:57,058] INFO Property socket.receive.buffer.bytes is overridden to 102400 (kafka.utils.VerifiableProperties)
[2016-11-04 18:17:57,059] INFO Property socket.request.max.bytes is overridden to 104857600 (kafka.utils.VerifiableProperties)
[2016-11-04 18:17:57,059] INFO Property socket.send.buffer.bytes is overridden to 102400 (kafka.utils.VerifiableProperties)
[2016-11-04 18:17:57,059] INFO Property zookeeper.connect is overridden to localhost:2181 (kafka.utils.VerifiableProperties)
[2016-11-04 18:17:57,059] INFO Property zookeeper.connection.timeout.ms is overridden to 6000 (kafka.utils.VerifiableProperties)
[2016-11-04 18:17:57,103] INFO [Kafka Server 0], starting (kafka.server.KafkaServer)
[2016-11-04 18:17:57,105] INFO [Kafka Server 0], Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-11-04 18:17:57,238] INFO Loading logs. (kafka.log.LogManager)
[2016-11-04 18:17:57,247] INFO Logs loading complete. (kafka.log.LogManager)
[2016-11-04 18:17:57,248] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-11-04 18:17:57,252] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-11-04 18:17:57,284] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2016-11-04 18:17:57,285] INFO [Socket Server on Broker 0], Started (kafka.network.SocketServer)
[2016-11-04 18:17:57,364] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-11-04 18:17:57,414] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-11-04 18:17:57,506] INFO Registered broker 0 at path /brokers/ids/0 with address localhost.localdomain:9092. (kafka.utils.ZkUtils$)
[2016-11-04 18:17:57,523] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-11-04 18:17:57,589] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-11-04 18:18:06,798] ERROR Closing socket for /127.0.0.1 because of error (kafka.network.Processor)
kafka.common.KafkaException: Wrong request type 16
	at kafka.api.RequestKeys$.deserializerForKey(RequestKeys.scala:64)
	at kafka.network.RequestChannel$Request.<init>(RequestChannel.scala:50)
	at kafka.network.Processor.read(SocketServer.scala:450)
	at kafka.network.Processor.run(SocketServer.scala:340)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:18:06,857] ERROR [KafkaApi-0] error when handling request ConsumerMetadataRequest(kafka-python-default-group,0,4,kafka-python-1.0.2) (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:70)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:171)
	at kafka.server.KafkaApis$$anonfun$19.apply(KafkaApis.scala:513)
	at kafka.server.KafkaApis$$anonfun$19.apply(KafkaApis.scala:503)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:92)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:503)
	at kafka.server.KafkaApis.handleConsumerMetadataRequest(KafkaApis.scala:607)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:69)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:59)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:18:07,051] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2016-11-04 18:18:07,058] INFO [KafkaApi-0] Auto creation of topic send_sms with 1 partitions and replication factor 1 is successful! (kafka.server.KafkaApis)
[2016-11-04 18:18:07,070] ERROR [KafkaApi-0] error when handling request ConsumerMetadataRequest(kafka-python-default-group,0,7,kafka-python-1.0.2) (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:70)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:171)
	at kafka.server.KafkaApis$$anonfun$19.apply(KafkaApis.scala:513)
	at kafka.server.KafkaApis$$anonfun$19.apply(KafkaApis.scala:503)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:92)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:503)
	at kafka.server.KafkaApis.handleConsumerMetadataRequest(KafkaApis.scala:607)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:69)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:59)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:18:07,111] ERROR [KafkaApi-0] error when handling request ConsumerMetadataRequest(kafka-python-default-group,0,8,kafka-python-1.0.2) (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:70)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:171)
	at kafka.server.KafkaApis$$anonfun$19.apply(KafkaApis.scala:513)
	at kafka.server.KafkaApis$$anonfun$19.apply(KafkaApis.scala:503)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:92)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:503)
	at kafka.server.KafkaApis.handleConsumerMetadataRequest(KafkaApis.scala:607)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:69)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:59)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:18:07,153] ERROR [KafkaApi-0] error when handling request ConsumerMetadataRequest(kafka-python-default-group,0,9,kafka-python-1.0.2) (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:70)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:171)
	at kafka.server.KafkaApis$$anonfun$19.apply(KafkaApis.scala:513)
	at kafka.server.KafkaApis$$anonfun$19.apply(KafkaApis.scala:503)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:92)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:503)
	at kafka.server.KafkaApis.handleConsumerMetadataRequest(KafkaApis.scala:607)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:69)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:59)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:18:07,193] ERROR [KafkaApi-0] error when handling request ConsumerMetadataRequest(kafka-python-default-group,0,10,kafka-python-1.0.2) (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:70)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:171)
	at kafka.server.KafkaApis$$anonfun$19.apply(KafkaApis.scala:513)
	at kafka.server.KafkaApis$$anonfun$19.apply(KafkaApis.scala:503)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:92)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:503)
	at kafka.server.KafkaApis.handleConsumerMetadataRequest(KafkaApis.scala:607)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:69)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:59)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:18:07,203] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [send_sms,0] (kafka.server.ReplicaFetcherManager)
[2016-11-04 18:18:07,240] ERROR [KafkaApi-0] error when handling request ConsumerMetadataRequest(kafka-python-default-group,0,12,kafka-python-1.0.2) (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 3 larger than available brokers: 1
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:70)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:171)
	at kafka.server.KafkaApis$$anonfun$19.apply(KafkaApis.scala:513)
	at kafka.server.KafkaApis$$anonfun$19.apply(KafkaApis.scala:503)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:92)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:503)
	at kafka.server.KafkaApis.handleConsumerMetadataRequest(KafkaApis.scala:607)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:69)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:59)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:18:07,242] INFO Completed load of log send_sms-0 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:07,245] INFO Created log for partition [send_sms,0] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 1073741824, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> delete, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:07,246] WARN Partition [send_sms,0] on broker 0: No checkpointed highwatermark is found for partition [send_sms,0] (kafka.cluster.Partition)
[2016-11-04 18:18:07,297] INFO Topic creation {"version":1,"partitions":{"45":[0],"34":[0],"12":[0],"8":[0],"19":[0],"23":[0],"4":[0],"40":[0],"15":[0],"11":[0],"9":[0],"44":[0],"33":[0],"22":[0],"26":[0],"37":[0],"13":[0],"46":[0],"24":[0],"35":[0],"16":[0],"5":[0],"10":[0],"48":[0],"21":[0],"43":[0],"32":[0],"49":[0],"6":[0],"36":[0],"1":[0],"39":[0],"17":[0],"25":[0],"14":[0],"47":[0],"31":[0],"42":[0],"0":[0],"20":[0],"27":[0],"2":[0],"38":[0],"18":[0],"30":[0],"7":[0],"29":[0],"41":[0],"3":[0],"28":[0]}} (kafka.admin.AdminUtils$)
[2016-11-04 18:18:07,341] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful! (kafka.server.KafkaApis)
[2016-11-04 18:18:08,037] ERROR Closing socket for /127.0.0.1 because of error (kafka.network.Processor)
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:384)
	at kafka.utils.Utils$.read(Utils.scala:380)
	at kafka.network.BoundedByteBufferReceive.readFrom(BoundedByteBufferReceive.scala:54)
	at kafka.network.Processor.read(SocketServer.scala:444)
	at kafka.network.Processor.run(SocketServer.scala:340)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:18:09,392] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-11-04 18:18:09,407] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,409] INFO Created log for partition [__consumer_offsets,0] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,410] WARN Partition [__consumer_offsets,0] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-11-04 18:18:09,412] INFO Loading offsets from [__consumer_offsets,0] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,415] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,417] INFO Finished loading offsets from [__consumer_offsets,0] in 5 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,417] INFO Created log for partition [__consumer_offsets,29] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,417] WARN Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2016-11-04 18:18:09,418] INFO Loading offsets from [__consumer_offsets,29] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,420] INFO Finished loading offsets from [__consumer_offsets,29] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,422] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,424] INFO Created log for partition [__consumer_offsets,48] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,424] WARN Partition [__consumer_offsets,48] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-11-04 18:18:09,425] INFO Loading offsets from [__consumer_offsets,48] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,427] INFO Finished loading offsets from [__consumer_offsets,48] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,430] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,432] INFO Created log for partition [__consumer_offsets,10] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,432] WARN Partition [__consumer_offsets,10] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2016-11-04 18:18:09,433] INFO Loading offsets from [__consumer_offsets,10] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,435] INFO Finished loading offsets from [__consumer_offsets,10] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,437] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,439] INFO Created log for partition [__consumer_offsets,45] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,440] WARN Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-11-04 18:18:09,440] INFO Loading offsets from [__consumer_offsets,45] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,442] INFO Finished loading offsets from [__consumer_offsets,45] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,445] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,447] INFO Created log for partition [__consumer_offsets,26] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,447] WARN Partition [__consumer_offsets,26] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2016-11-04 18:18:09,448] INFO Loading offsets from [__consumer_offsets,26] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,450] INFO Finished loading offsets from [__consumer_offsets,26] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,452] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,454] INFO Created log for partition [__consumer_offsets,7] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,454] WARN Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2016-11-04 18:18:09,455] INFO Loading offsets from [__consumer_offsets,7] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,457] INFO Finished loading offsets from [__consumer_offsets,7] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,459] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,461] INFO Created log for partition [__consumer_offsets,42] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,461] WARN Partition [__consumer_offsets,42] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-11-04 18:18:09,462] INFO Loading offsets from [__consumer_offsets,42] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,464] INFO Finished loading offsets from [__consumer_offsets,42] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,468] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,470] INFO Created log for partition [__consumer_offsets,4] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,470] WARN Partition [__consumer_offsets,4] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2016-11-04 18:18:09,471] INFO Loading offsets from [__consumer_offsets,4] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,473] INFO Finished loading offsets from [__consumer_offsets,4] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,474] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,476] INFO Created log for partition [__consumer_offsets,23] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,477] WARN Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2016-11-04 18:18:09,477] INFO Loading offsets from [__consumer_offsets,23] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,479] INFO Finished loading offsets from [__consumer_offsets,23] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,483] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,485] INFO Created log for partition [__consumer_offsets,1] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,485] WARN Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2016-11-04 18:18:09,486] INFO Loading offsets from [__consumer_offsets,1] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,488] INFO Finished loading offsets from [__consumer_offsets,1] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,491] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,493] INFO Created log for partition [__consumer_offsets,39] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,493] WARN Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-11-04 18:18:09,494] INFO Loading offsets from [__consumer_offsets,39] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,496] INFO Finished loading offsets from [__consumer_offsets,39] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,497] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,499] INFO Created log for partition [__consumer_offsets,20] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,499] WARN Partition [__consumer_offsets,20] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2016-11-04 18:18:09,500] INFO Loading offsets from [__consumer_offsets,20] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,502] INFO Finished loading offsets from [__consumer_offsets,20] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,505] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,507] INFO Created log for partition [__consumer_offsets,17] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,508] WARN Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2016-11-04 18:18:09,508] INFO Loading offsets from [__consumer_offsets,17] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,510] INFO Finished loading offsets from [__consumer_offsets,17] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,513] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,515] INFO Created log for partition [__consumer_offsets,36] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,516] WARN Partition [__consumer_offsets,36] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-11-04 18:18:09,516] INFO Loading offsets from [__consumer_offsets,36] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,518] INFO Finished loading offsets from [__consumer_offsets,36] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,520] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,522] INFO Created log for partition [__consumer_offsets,14] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,523] WARN Partition [__consumer_offsets,14] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2016-11-04 18:18:09,523] INFO Loading offsets from [__consumer_offsets,14] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,525] INFO Finished loading offsets from [__consumer_offsets,14] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,526] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,529] INFO Created log for partition [__consumer_offsets,33] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,530] WARN Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-11-04 18:18:09,530] INFO Loading offsets from [__consumer_offsets,33] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,532] INFO Finished loading offsets from [__consumer_offsets,33] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,534] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,536] INFO Created log for partition [__consumer_offsets,49] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,536] WARN Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2016-11-04 18:18:09,537] INFO Loading offsets from [__consumer_offsets,49] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,539] INFO Finished loading offsets from [__consumer_offsets,49] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,542] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,544] INFO Created log for partition [__consumer_offsets,11] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,545] WARN Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2016-11-04 18:18:09,545] INFO Loading offsets from [__consumer_offsets,11] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,547] INFO Finished loading offsets from [__consumer_offsets,11] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,548] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,550] INFO Created log for partition [__consumer_offsets,30] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,551] WARN Partition [__consumer_offsets,30] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-11-04 18:18:09,551] INFO Loading offsets from [__consumer_offsets,30] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,553] INFO Finished loading offsets from [__consumer_offsets,30] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,557] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,559] INFO Created log for partition [__consumer_offsets,46] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,559] WARN Partition [__consumer_offsets,46] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2016-11-04 18:18:09,560] INFO Loading offsets from [__consumer_offsets,46] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,561] INFO Finished loading offsets from [__consumer_offsets,46] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,564] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,566] INFO Created log for partition [__consumer_offsets,27] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,567] WARN Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-11-04 18:18:09,567] INFO Loading offsets from [__consumer_offsets,27] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,569] INFO Finished loading offsets from [__consumer_offsets,27] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,570] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,572] INFO Created log for partition [__consumer_offsets,8] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,573] WARN Partition [__consumer_offsets,8] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2016-11-04 18:18:09,573] INFO Loading offsets from [__consumer_offsets,8] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,575] INFO Finished loading offsets from [__consumer_offsets,8] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,578] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,580] INFO Created log for partition [__consumer_offsets,24] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,580] WARN Partition [__consumer_offsets,24] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-11-04 18:18:09,581] INFO Loading offsets from [__consumer_offsets,24] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,582] INFO Finished loading offsets from [__consumer_offsets,24] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,584] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,586] INFO Created log for partition [__consumer_offsets,43] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,586] WARN Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2016-11-04 18:18:09,587] INFO Loading offsets from [__consumer_offsets,43] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,588] INFO Finished loading offsets from [__consumer_offsets,43] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,590] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,592] INFO Created log for partition [__consumer_offsets,5] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,592] WARN Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2016-11-04 18:18:09,593] INFO Loading offsets from [__consumer_offsets,5] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,595] INFO Finished loading offsets from [__consumer_offsets,5] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,596] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,598] INFO Created log for partition [__consumer_offsets,21] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,598] WARN Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-11-04 18:18:09,599] INFO Loading offsets from [__consumer_offsets,21] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,601] INFO Finished loading offsets from [__consumer_offsets,21] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,602] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,604] INFO Created log for partition [__consumer_offsets,40] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,604] WARN Partition [__consumer_offsets,40] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2016-11-04 18:18:09,605] INFO Loading offsets from [__consumer_offsets,40] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,607] INFO Finished loading offsets from [__consumer_offsets,40] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,612] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,615] INFO Created log for partition [__consumer_offsets,2] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,615] WARN Partition [__consumer_offsets,2] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2016-11-04 18:18:09,616] INFO Loading offsets from [__consumer_offsets,2] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,618] INFO Finished loading offsets from [__consumer_offsets,2] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,620] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,622] INFO Created log for partition [__consumer_offsets,37] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,623] WARN Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2016-11-04 18:18:09,624] INFO Loading offsets from [__consumer_offsets,37] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,625] INFO Finished loading offsets from [__consumer_offsets,37] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,630] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,632] INFO Created log for partition [__consumer_offsets,18] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,633] WARN Partition [__consumer_offsets,18] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-11-04 18:18:09,633] INFO Loading offsets from [__consumer_offsets,18] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,635] INFO Finished loading offsets from [__consumer_offsets,18] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,637] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,639] INFO Created log for partition [__consumer_offsets,15] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,640] WARN Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-11-04 18:18:09,641] INFO Loading offsets from [__consumer_offsets,15] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,642] INFO Finished loading offsets from [__consumer_offsets,15] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,645] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,648] INFO Created log for partition [__consumer_offsets,34] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,649] WARN Partition [__consumer_offsets,34] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2016-11-04 18:18:09,650] INFO Loading offsets from [__consumer_offsets,34] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,651] INFO Finished loading offsets from [__consumer_offsets,34] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,654] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,656] INFO Created log for partition [__consumer_offsets,12] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,656] WARN Partition [__consumer_offsets,12] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-11-04 18:18:09,657] INFO Loading offsets from [__consumer_offsets,12] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,658] INFO Finished loading offsets from [__consumer_offsets,12] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,660] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,662] INFO Created log for partition [__consumer_offsets,31] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,663] WARN Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2016-11-04 18:18:09,664] INFO Loading offsets from [__consumer_offsets,31] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,665] INFO Finished loading offsets from [__consumer_offsets,31] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,667] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,669] INFO Created log for partition [__consumer_offsets,9] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,669] WARN Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-11-04 18:18:09,669] INFO Loading offsets from [__consumer_offsets,9] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,671] INFO Finished loading offsets from [__consumer_offsets,9] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,675] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,677] INFO Created log for partition [__consumer_offsets,47] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,678] WARN Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2016-11-04 18:18:09,678] INFO Loading offsets from [__consumer_offsets,47] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,688] INFO Finished loading offsets from [__consumer_offsets,47] in 9 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,693] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,695] INFO Created log for partition [__consumer_offsets,19] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,696] WARN Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2016-11-04 18:18:09,696] INFO Loading offsets from [__consumer_offsets,19] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,698] INFO Finished loading offsets from [__consumer_offsets,19] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,703] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,704] INFO Created log for partition [__consumer_offsets,28] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,705] WARN Partition [__consumer_offsets,28] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2016-11-04 18:18:09,706] INFO Loading offsets from [__consumer_offsets,28] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,707] INFO Finished loading offsets from [__consumer_offsets,28] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,709] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,711] INFO Created log for partition [__consumer_offsets,38] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,711] WARN Partition [__consumer_offsets,38] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2016-11-04 18:18:09,712] INFO Loading offsets from [__consumer_offsets,38] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,714] INFO Finished loading offsets from [__consumer_offsets,38] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,717] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,718] INFO Created log for partition [__consumer_offsets,35] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,719] WARN Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2016-11-04 18:18:09,719] INFO Loading offsets from [__consumer_offsets,35] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,721] INFO Finished loading offsets from [__consumer_offsets,35] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,722] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,724] INFO Created log for partition [__consumer_offsets,44] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,725] WARN Partition [__consumer_offsets,44] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2016-11-04 18:18:09,725] INFO Loading offsets from [__consumer_offsets,44] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,727] INFO Finished loading offsets from [__consumer_offsets,44] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,731] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,732] INFO Created log for partition [__consumer_offsets,6] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,733] WARN Partition [__consumer_offsets,6] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-11-04 18:18:09,733] INFO Loading offsets from [__consumer_offsets,6] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,735] INFO Finished loading offsets from [__consumer_offsets,6] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,736] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,738] INFO Created log for partition [__consumer_offsets,25] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,738] WARN Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2016-11-04 18:18:09,739] INFO Loading offsets from [__consumer_offsets,25] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,740] INFO Finished loading offsets from [__consumer_offsets,25] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,741] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,743] INFO Created log for partition [__consumer_offsets,16] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,743] WARN Partition [__consumer_offsets,16] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2016-11-04 18:18:09,744] INFO Loading offsets from [__consumer_offsets,16] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,745] INFO Finished loading offsets from [__consumer_offsets,16] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,750] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,752] INFO Created log for partition [__consumer_offsets,22] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,752] WARN Partition [__consumer_offsets,22] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2016-11-04 18:18:09,753] INFO Loading offsets from [__consumer_offsets,22] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,754] INFO Finished loading offsets from [__consumer_offsets,22] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,758] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,759] INFO Created log for partition [__consumer_offsets,41] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,760] WARN Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2016-11-04 18:18:09,761] INFO Loading offsets from [__consumer_offsets,41] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,762] INFO Finished loading offsets from [__consumer_offsets,41] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,763] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,765] INFO Created log for partition [__consumer_offsets,32] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,765] WARN Partition [__consumer_offsets,32] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2016-11-04 18:18:09,766] INFO Loading offsets from [__consumer_offsets,32] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,767] INFO Finished loading offsets from [__consumer_offsets,32] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,769] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,771] INFO Created log for partition [__consumer_offsets,3] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,772] WARN Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-11-04 18:18:09,772] INFO Loading offsets from [__consumer_offsets,3] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,774] INFO Finished loading offsets from [__consumer_offsets,3] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:09,777] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:18:09,779] INFO Created log for partition [__consumer_offsets,13] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-11-04 18:18:09,779] WARN Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2016-11-04 18:18:09,780] INFO Loading offsets from [__consumer_offsets,13] (kafka.server.OffsetManager)
[2016-11-04 18:18:09,781] INFO Finished loading offsets from [__consumer_offsets,13] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:18:20,079] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2016-11-04 18:18:20,085] ERROR Closing socket for /127.0.0.1 because of error (kafka.network.Processor)
kafka.common.KafkaException: Wrong request type 16
	at kafka.api.RequestKeys$.deserializerForKey(RequestKeys.scala:64)
	at kafka.network.RequestChannel$Request.<init>(RequestChannel.scala:50)
	at kafka.network.Processor.read(SocketServer.scala:450)
	at kafka.network.Processor.run(SocketServer.scala:340)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:23:52,158] ERROR Closing socket for /127.0.0.1 because of error (kafka.network.Processor)
java.io.IOException: Broken pipe
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:492)
	at kafka.api.TopicDataSend.writeTo(FetchResponse.scala:123)
	at kafka.network.MultiSend.writeTo(Transmission.scala:101)
	at kafka.api.FetchResponseSend.writeTo(FetchResponse.scala:231)
	at kafka.network.Processor.write(SocketServer.scala:472)
	at kafka.network.Processor.run(SocketServer.scala:342)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:23:53,085] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2016-11-04 18:23:53,092] ERROR Closing socket for /127.0.0.1 because of error (kafka.network.Processor)
kafka.common.KafkaException: Wrong request type 16
	at kafka.api.RequestKeys$.deserializerForKey(RequestKeys.scala:64)
	at kafka.network.RequestChannel$Request.<init>(RequestChannel.scala:50)
	at kafka.network.Processor.read(SocketServer.scala:450)
	at kafka.network.Processor.run(SocketServer.scala:340)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:26:03,385] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2016-11-04 18:26:03,945] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2016-11-04 18:26:03,953] ERROR Closing socket for /127.0.0.1 because of error (kafka.network.Processor)
kafka.common.KafkaException: Wrong request type 16
	at kafka.api.RequestKeys$.deserializerForKey(RequestKeys.scala:64)
	at kafka.network.RequestChannel$Request.<init>(RequestChannel.scala:50)
	at kafka.network.Processor.read(SocketServer.scala:450)
	at kafka.network.Processor.run(SocketServer.scala:340)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:26:48,160] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2016-11-04 18:26:50,725] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2016-11-04 18:26:50,732] ERROR Closing socket for /127.0.0.1 because of error (kafka.network.Processor)
kafka.common.KafkaException: Wrong request type 16
	at kafka.api.RequestKeys$.deserializerForKey(RequestKeys.scala:64)
	at kafka.network.RequestChannel$Request.<init>(RequestChannel.scala:50)
	at kafka.network.Processor.read(SocketServer.scala:450)
	at kafka.network.Processor.run(SocketServer.scala:340)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:27:24,075] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2016-11-04 18:40:18,714] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2016-11-04 18:40:18,730] ERROR Closing socket for /127.0.0.1 because of error (kafka.network.Processor)
kafka.common.KafkaException: Wrong request type 16
	at kafka.api.RequestKeys$.deserializerForKey(RequestKeys.scala:64)
	at kafka.network.RequestChannel$Request.<init>(RequestChannel.scala:50)
	at kafka.network.Processor.read(SocketServer.scala:450)
	at kafka.network.Processor.run(SocketServer.scala:340)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:42:05,730] ERROR Closing socket for /127.0.0.1 because of error (kafka.network.Processor)
java.io.IOException: Broken pipe
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:492)
	at kafka.api.TopicDataSend.writeTo(FetchResponse.scala:123)
	at kafka.network.MultiSend.writeTo(Transmission.scala:101)
	at kafka.api.FetchResponseSend.writeTo(FetchResponse.scala:231)
	at kafka.network.Processor.write(SocketServer.scala:472)
	at kafka.network.Processor.run(SocketServer.scala:342)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:42:21,966] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2016-11-04 18:42:21,974] ERROR Closing socket for /127.0.0.1 because of error (kafka.network.Processor)
kafka.common.KafkaException: Wrong request type 16
	at kafka.api.RequestKeys$.deserializerForKey(RequestKeys.scala:64)
	at kafka.network.RequestChannel$Request.<init>(RequestChannel.scala:50)
	at kafka.network.Processor.read(SocketServer.scala:450)
	at kafka.network.Processor.run(SocketServer.scala:340)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:43:56,366] ERROR Closing socket for /127.0.0.1 because of error (kafka.network.Processor)
java.io.IOException: Broken pipe
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:492)
	at kafka.api.TopicDataSend.writeTo(FetchResponse.scala:123)
	at kafka.network.MultiSend.writeTo(Transmission.scala:101)
	at kafka.api.FetchResponseSend.writeTo(FetchResponse.scala:231)
	at kafka.network.Processor.write(SocketServer.scala:472)
	at kafka.network.Processor.run(SocketServer.scala:342)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:52:07,428] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2016-11-04 18:52:08,033] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2016-11-04 18:52:08,045] ERROR Closing socket for /127.0.0.1 because of error (kafka.network.Processor)
kafka.common.KafkaException: Wrong request type 16
	at kafka.api.RequestKeys$.deserializerForKey(RequestKeys.scala:64)
	at kafka.network.RequestChannel$Request.<init>(RequestChannel.scala:50)
	at kafka.network.Processor.read(SocketServer.scala:450)
	at kafka.network.Processor.run(SocketServer.scala:340)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:57:22,119] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2016-11-04 18:57:22,120] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2016-11-04 18:57:22,141] INFO [Kafka Server 0], Controlled shutdown succeeded (kafka.server.KafkaServer)
[2016-11-04 18:57:22,142] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2016-11-04 18:57:22,143] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[2016-11-04 18:57:22,147] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[2016-11-04 18:57:22,148] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2016-11-04 18:57:22,150] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2016-11-04 18:57:22,336] INFO [Replica Manager on Broker 0]: Shut down (kafka.server.ReplicaManager)
[2016-11-04 18:57:22,337] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2016-11-04 18:57:22,338] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2016-11-04 18:57:22,346] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[2016-11-04 18:57:22,347] INFO Shutting down. (kafka.log.LogManager)
[2016-11-04 18:57:22,387] INFO Shutdown complete. (kafka.log.LogManager)
[2016-11-04 18:57:22,405] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2016-11-04 18:57:29,317] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-11-04 18:57:29,453] INFO Property broker.id is overridden to 0 (kafka.utils.VerifiableProperties)
[2016-11-04 18:57:29,453] INFO Property log.cleaner.enable is overridden to false (kafka.utils.VerifiableProperties)
[2016-11-04 18:57:29,454] INFO Property log.dirs is overridden to /tmp/kafka-logs (kafka.utils.VerifiableProperties)
[2016-11-04 18:57:29,455] INFO Property log.retention.check.interval.ms is overridden to 300000 (kafka.utils.VerifiableProperties)
[2016-11-04 18:57:29,455] INFO Property log.retention.hours is overridden to 168 (kafka.utils.VerifiableProperties)
[2016-11-04 18:57:29,456] INFO Property log.segment.bytes is overridden to 1073741824 (kafka.utils.VerifiableProperties)
[2016-11-04 18:57:29,456] INFO Property num.io.threads is overridden to 8 (kafka.utils.VerifiableProperties)
[2016-11-04 18:57:29,457] INFO Property num.network.threads is overridden to 3 (kafka.utils.VerifiableProperties)
[2016-11-04 18:57:29,457] INFO Property num.partitions is overridden to 1 (kafka.utils.VerifiableProperties)
[2016-11-04 18:57:29,458] INFO Property num.recovery.threads.per.data.dir is overridden to 1 (kafka.utils.VerifiableProperties)
[2016-11-04 18:57:29,458] INFO Property port is overridden to 9092 (kafka.utils.VerifiableProperties)
[2016-11-04 18:57:29,458] INFO Property socket.receive.buffer.bytes is overridden to 102400 (kafka.utils.VerifiableProperties)
[2016-11-04 18:57:29,459] INFO Property socket.request.max.bytes is overridden to 104857600 (kafka.utils.VerifiableProperties)
[2016-11-04 18:57:29,459] INFO Property socket.send.buffer.bytes is overridden to 102400 (kafka.utils.VerifiableProperties)
[2016-11-04 18:57:29,459] INFO Property zookeeper.connect is overridden to localhost:2181 (kafka.utils.VerifiableProperties)
[2016-11-04 18:57:29,460] INFO Property zookeeper.connection.timeout.ms is overridden to 6000 (kafka.utils.VerifiableProperties)
[2016-11-04 18:57:29,551] INFO [Kafka Server 0], starting (kafka.server.KafkaServer)
[2016-11-04 18:57:29,553] INFO [Kafka Server 0], Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-11-04 18:57:29,851] INFO Loading logs. (kafka.log.LogManager)
[2016-11-04 18:57:30,513] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,522] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,527] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,534] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,543] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,549] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,560] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,567] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,573] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,579] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,585] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,591] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,597] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,603] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,609] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,616] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,623] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,628] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,634] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,639] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,645] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,723] INFO Completed load of log send_sms-0 with log end offset 2 (kafka.log.Log)
[2016-11-04 18:57:30,732] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,739] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,745] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,751] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,756] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,761] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,766] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,771] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,779] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,788] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,794] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,799] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,805] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,810] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,815] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,820] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,824] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,828] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,832] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,836] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,840] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,844] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,849] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,852] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,856] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,860] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,864] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,868] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,872] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2016-11-04 18:57:30,876] INFO Logs loading complete. (kafka.log.LogManager)
[2016-11-04 18:57:30,877] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-11-04 18:57:30,879] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-11-04 18:57:30,910] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2016-11-04 18:57:30,911] INFO [Socket Server on Broker 0], Started (kafka.network.SocketServer)
[2016-11-04 18:57:30,994] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-11-04 18:57:31,129] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-11-04 18:57:32,804] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-11-04 18:57:32,867] INFO Registered broker 0 at path /brokers/ids/0 with address localhost.localdomain:9092. (kafka.utils.ZkUtils$)
[2016-11-04 18:57:32,893] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-11-04 18:57:33,519] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[send_sms,0],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-11-04 18:57:33,658] INFO Loading offsets from [__consumer_offsets,0] (kafka.server.OffsetManager)
[2016-11-04 18:57:33,665] INFO Finished loading offsets from [__consumer_offsets,0] in 6 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:33,918] INFO Loading offsets from [__consumer_offsets,29] (kafka.server.OffsetManager)
[2016-11-04 18:57:33,961] INFO Finished loading offsets from [__consumer_offsets,29] in 4 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:33,976] INFO Loading offsets from [__consumer_offsets,48] (kafka.server.OffsetManager)
[2016-11-04 18:57:33,978] INFO Finished loading offsets from [__consumer_offsets,48] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,112] INFO Loading offsets from [__consumer_offsets,10] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,114] INFO Finished loading offsets from [__consumer_offsets,10] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,126] INFO Loading offsets from [__consumer_offsets,45] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,128] INFO Finished loading offsets from [__consumer_offsets,45] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,269] INFO Loading offsets from [__consumer_offsets,26] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,272] INFO Finished loading offsets from [__consumer_offsets,26] in 3 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,279] INFO Loading offsets from [__consumer_offsets,7] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,280] INFO Finished loading offsets from [__consumer_offsets,7] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,291] INFO Loading offsets from [__consumer_offsets,42] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,292] INFO Finished loading offsets from [__consumer_offsets,42] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,357] INFO Loading offsets from [__consumer_offsets,4] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,360] INFO Finished loading offsets from [__consumer_offsets,4] in 3 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,440] INFO Loading offsets from [__consumer_offsets,23] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,442] INFO Finished loading offsets from [__consumer_offsets,23] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,450] INFO Loading offsets from [__consumer_offsets,1] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,452] INFO Finished loading offsets from [__consumer_offsets,1] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,545] INFO Loading offsets from [__consumer_offsets,20] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,548] INFO Finished loading offsets from [__consumer_offsets,20] in 3 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,555] INFO Loading offsets from [__consumer_offsets,39] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,558] INFO Finished loading offsets from [__consumer_offsets,39] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,567] INFO Loading offsets from [__consumer_offsets,17] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,570] INFO Finished loading offsets from [__consumer_offsets,17] in 3 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,578] INFO Loading offsets from [__consumer_offsets,36] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,580] INFO Finished loading offsets from [__consumer_offsets,36] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,586] INFO Loading offsets from [__consumer_offsets,14] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,587] INFO Finished loading offsets from [__consumer_offsets,14] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,599] INFO Loading offsets from [__consumer_offsets,33] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,600] INFO Finished loading offsets from [__consumer_offsets,33] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,605] INFO Loading offsets from [__consumer_offsets,49] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,606] INFO Finished loading offsets from [__consumer_offsets,49] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,610] INFO Loading offsets from [__consumer_offsets,11] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,612] INFO Finished loading offsets from [__consumer_offsets,11] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,620] INFO Loading offsets from [__consumer_offsets,30] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,621] INFO Finished loading offsets from [__consumer_offsets,30] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,831] INFO Loading offsets from [__consumer_offsets,46] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,832] INFO Finished loading offsets from [__consumer_offsets,46] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,843] INFO Loading offsets from [__consumer_offsets,27] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,845] INFO Finished loading offsets from [__consumer_offsets,27] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,937] INFO Loading offsets from [__consumer_offsets,8] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,939] INFO Finished loading offsets from [__consumer_offsets,8] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:34,948] INFO Loading offsets from [__consumer_offsets,24] (kafka.server.OffsetManager)
[2016-11-04 18:57:34,950] INFO Finished loading offsets from [__consumer_offsets,24] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,047] INFO Loading offsets from [__consumer_offsets,43] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,049] INFO Finished loading offsets from [__consumer_offsets,43] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,056] INFO Loading offsets from [__consumer_offsets,5] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,058] INFO Finished loading offsets from [__consumer_offsets,5] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,150] INFO Loading offsets from [__consumer_offsets,21] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,152] INFO Finished loading offsets from [__consumer_offsets,21] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,166] INFO Loading offsets from [__consumer_offsets,40] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,167] INFO Finished loading offsets from [__consumer_offsets,40] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,256] INFO Loading offsets from [__consumer_offsets,2] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,257] INFO Finished loading offsets from [__consumer_offsets,2] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,261] INFO Loading offsets from [__consumer_offsets,37] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,263] INFO Finished loading offsets from [__consumer_offsets,37] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,307] INFO Loading offsets from [__consumer_offsets,18] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,308] INFO Finished loading offsets from [__consumer_offsets,18] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,314] INFO Loading offsets from [__consumer_offsets,15] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,318] INFO Finished loading offsets from [__consumer_offsets,15] in 3 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,326] INFO Loading offsets from [__consumer_offsets,34] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,327] INFO Finished loading offsets from [__consumer_offsets,34] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,344] INFO Loading offsets from [__consumer_offsets,12] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,349] INFO Finished loading offsets from [__consumer_offsets,12] in 4 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,548] INFO Loading offsets from [__consumer_offsets,31] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,552] INFO Finished loading offsets from [__consumer_offsets,31] in 4 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,555] INFO Loading offsets from [__consumer_offsets,9] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,560] INFO Finished loading offsets from [__consumer_offsets,9] in 4 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,653] INFO Loading offsets from [__consumer_offsets,47] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,656] INFO Finished loading offsets from [__consumer_offsets,47] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,662] INFO Loading offsets from [__consumer_offsets,19] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,664] INFO Finished loading offsets from [__consumer_offsets,19] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,755] INFO Loading offsets from [__consumer_offsets,28] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,758] INFO Finished loading offsets from [__consumer_offsets,28] in 3 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,854] INFO Loading offsets from [__consumer_offsets,38] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,856] INFO Finished loading offsets from [__consumer_offsets,38] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,862] INFO Loading offsets from [__consumer_offsets,35] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,959] INFO Finished loading offsets from [__consumer_offsets,35] in 96 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,967] INFO Loading offsets from [__consumer_offsets,44] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,969] INFO Finished loading offsets from [__consumer_offsets,44] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:35,976] INFO Loading offsets from [__consumer_offsets,6] (kafka.server.OffsetManager)
[2016-11-04 18:57:35,977] INFO Finished loading offsets from [__consumer_offsets,6] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:36,060] INFO Loading offsets from [__consumer_offsets,25] (kafka.server.OffsetManager)
[2016-11-04 18:57:36,062] INFO Finished loading offsets from [__consumer_offsets,25] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:36,067] INFO Loading offsets from [__consumer_offsets,16] (kafka.server.OffsetManager)
[2016-11-04 18:57:36,068] INFO Finished loading offsets from [__consumer_offsets,16] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:36,072] INFO Loading offsets from [__consumer_offsets,22] (kafka.server.OffsetManager)
[2016-11-04 18:57:36,074] INFO Finished loading offsets from [__consumer_offsets,22] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:36,160] INFO Loading offsets from [__consumer_offsets,41] (kafka.server.OffsetManager)
[2016-11-04 18:57:36,162] INFO Finished loading offsets from [__consumer_offsets,41] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:36,168] INFO Loading offsets from [__consumer_offsets,32] (kafka.server.OffsetManager)
[2016-11-04 18:57:36,170] INFO Finished loading offsets from [__consumer_offsets,32] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:36,260] INFO Loading offsets from [__consumer_offsets,3] (kafka.server.OffsetManager)
[2016-11-04 18:57:36,262] INFO Finished loading offsets from [__consumer_offsets,3] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:36,267] INFO Loading offsets from [__consumer_offsets,13] (kafka.server.OffsetManager)
[2016-11-04 18:57:36,269] INFO Finished loading offsets from [__consumer_offsets,13] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,211] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[send_sms,0],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-11-04 18:57:37,224] INFO Loading offsets from [__consumer_offsets,29] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,224] INFO Loading offsets from [__consumer_offsets,48] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,224] INFO Loading offsets from [__consumer_offsets,10] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,224] INFO Loading offsets from [__consumer_offsets,0] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,231] INFO Loading offsets from [__consumer_offsets,45] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,226] INFO Finished loading offsets from [__consumer_offsets,29] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,232] INFO Loading offsets from [__consumer_offsets,26] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,232] INFO Loading offsets from [__consumer_offsets,7] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,233] INFO Finished loading offsets from [__consumer_offsets,48] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,233] INFO Loading offsets from [__consumer_offsets,42] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,233] INFO Finished loading offsets from [__consumer_offsets,26] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,233] INFO Loading offsets from [__consumer_offsets,4] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,233] INFO Finished loading offsets from [__consumer_offsets,7] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,234] INFO Loading offsets from [__consumer_offsets,23] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,234] INFO Finished loading offsets from [__consumer_offsets,42] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,234] INFO Loading offsets from [__consumer_offsets,1] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,235] INFO Finished loading offsets from [__consumer_offsets,4] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,235] INFO Loading offsets from [__consumer_offsets,20] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,265] INFO Finished loading offsets from [__consumer_offsets,1] in 30 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,265] INFO Finished loading offsets from [__consumer_offsets,23] in 31 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,265] INFO Finished loading offsets from [__consumer_offsets,20] in 30 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,268] INFO Finished loading offsets from [__consumer_offsets,0] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,269] INFO Finished loading offsets from [__consumer_offsets,10] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,269] INFO Loading offsets from [__consumer_offsets,39] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,270] INFO Finished loading offsets from [__consumer_offsets,39] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,272] INFO Finished loading offsets from [__consumer_offsets,45] in 6 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,272] INFO Loading offsets from [__consumer_offsets,17] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,273] INFO Finished loading offsets from [__consumer_offsets,17] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,274] INFO Loading offsets from [__consumer_offsets,36] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,275] INFO Loading offsets from [__consumer_offsets,14] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,275] INFO Finished loading offsets from [__consumer_offsets,36] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,275] INFO Loading offsets from [__consumer_offsets,33] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,277] INFO Finished loading offsets from [__consumer_offsets,33] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,277] INFO Finished loading offsets from [__consumer_offsets,14] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,277] INFO Loading offsets from [__consumer_offsets,49] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,277] INFO Loading offsets from [__consumer_offsets,11] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,279] INFO Finished loading offsets from [__consumer_offsets,11] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,279] INFO Loading offsets from [__consumer_offsets,30] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,279] INFO Finished loading offsets from [__consumer_offsets,49] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,280] INFO Loading offsets from [__consumer_offsets,46] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,280] INFO Loading offsets from [__consumer_offsets,27] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,280] INFO Loading offsets from [__consumer_offsets,8] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,280] INFO Finished loading offsets from [__consumer_offsets,30] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,281] INFO Loading offsets from [__consumer_offsets,24] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,281] INFO Finished loading offsets from [__consumer_offsets,46] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,281] INFO Loading offsets from [__consumer_offsets,43] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,282] INFO Finished loading offsets from [__consumer_offsets,27] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,282] INFO Finished loading offsets from [__consumer_offsets,8] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,282] INFO Loading offsets from [__consumer_offsets,21] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,282] INFO Loading offsets from [__consumer_offsets,2] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,283] INFO Finished loading offsets from [__consumer_offsets,43] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,283] INFO Loading offsets from [__consumer_offsets,37] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,284] INFO Finished loading offsets from [__consumer_offsets,2] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,284] INFO Loading offsets from [__consumer_offsets,18] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,284] INFO Finished loading offsets from [__consumer_offsets,21] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,284] INFO Loading offsets from [__consumer_offsets,15] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,284] INFO Finished loading offsets from [__consumer_offsets,37] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,285] INFO Loading offsets from [__consumer_offsets,34] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,285] INFO Finished loading offsets from [__consumer_offsets,18] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,286] INFO Loading offsets from [__consumer_offsets,12] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,286] INFO Finished loading offsets from [__consumer_offsets,34] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,286] INFO Finished loading offsets from [__consumer_offsets,15] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,286] INFO Loading offsets from [__consumer_offsets,9] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,286] INFO Loading offsets from [__consumer_offsets,47] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,287] INFO Finished loading offsets from [__consumer_offsets,12] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,282] INFO Loading offsets from [__consumer_offsets,5] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,288] INFO Loading offsets from [__consumer_offsets,38] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,290] INFO Finished loading offsets from [__consumer_offsets,38] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,290] INFO Loading offsets from [__consumer_offsets,35] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,288] INFO Finished loading offsets from [__consumer_offsets,9] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,287] INFO Finished loading offsets from [__consumer_offsets,24] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,287] INFO Loading offsets from [__consumer_offsets,19] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,287] INFO Loading offsets from [__consumer_offsets,28] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,291] INFO Loading offsets from [__consumer_offsets,6] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,292] INFO Finished loading offsets from [__consumer_offsets,28] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,286] INFO Loading offsets from [__consumer_offsets,31] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,282] INFO Loading offsets from [__consumer_offsets,40] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,293] INFO Finished loading offsets from [__consumer_offsets,47] in 7 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,293] INFO Finished loading offsets from [__consumer_offsets,19] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,291] INFO Loading offsets from [__consumer_offsets,44] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,290] INFO Finished loading offsets from [__consumer_offsets,5] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,295] INFO Loading offsets from [__consumer_offsets,16] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,294] INFO Loading offsets from [__consumer_offsets,25] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,295] INFO Finished loading offsets from [__consumer_offsets,44] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,296] INFO Loading offsets from [__consumer_offsets,41] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,296] INFO Finished loading offsets from [__consumer_offsets,35] in 4 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,296] INFO Loading offsets from [__consumer_offsets,22] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,296] INFO Loading offsets from [__consumer_offsets,32] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,297] INFO Finished loading offsets from [__consumer_offsets,41] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,297] INFO Finished loading offsets from [__consumer_offsets,6] in 3 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,300] INFO Finished loading offsets from [__consumer_offsets,22] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,304] INFO Loading offsets from [__consumer_offsets,13] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,305] INFO Finished loading offsets from [__consumer_offsets,40] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,305] INFO Finished loading offsets from [__consumer_offsets,31] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,306] INFO Finished loading offsets from [__consumer_offsets,13] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,307] INFO Finished loading offsets from [__consumer_offsets,25] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,307] INFO Loading offsets from [__consumer_offsets,3] (kafka.server.OffsetManager)
[2016-11-04 18:57:37,309] INFO Finished loading offsets from [__consumer_offsets,3] in 1 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,313] INFO Finished loading offsets from [__consumer_offsets,32] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:37,317] INFO Finished loading offsets from [__consumer_offsets,16] in 2 milliseconds. (kafka.server.OffsetManager)
[2016-11-04 18:57:40,536] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2016-11-04 18:57:40,830] ERROR Closing socket for /127.0.0.1 because of error (kafka.network.Processor)
kafka.common.KafkaException: Wrong request type 16
	at kafka.api.RequestKeys$.deserializerForKey(RequestKeys.scala:64)
	at kafka.network.RequestChannel$Request.<init>(RequestChannel.scala:50)
	at kafka.network.Processor.read(SocketServer.scala:450)
	at kafka.network.Processor.run(SocketServer.scala:340)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-04 18:57:48,908] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2016-11-04 18:57:48,916] ERROR Closing socket for /127.0.0.1 because of error (kafka.network.Processor)
kafka.common.KafkaException: Wrong request type 16
	at kafka.api.RequestKeys$.deserializerForKey(RequestKeys.scala:64)
	at kafka.network.RequestChannel$Request.<init>(RequestChannel.scala:50)
	at kafka.network.Processor.read(SocketServer.scala:450)
	at kafka.network.Processor.run(SocketServer.scala:340)
	at java.lang.Thread.run(Thread.java:745)
